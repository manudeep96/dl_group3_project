{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3vlWylJgV47",
        "outputId": "f4812d50-344e-4b74-8381-50c3e5fa52ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  liar_dataset.zip\n",
            "  inflating: README                  \n",
            "  inflating: test.tsv                \n",
            "  inflating: train.tsv               \n",
            "  inflating: valid.tsv               \n"
          ]
        }
      ],
      "source": [
        "!unzip liar_dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Analysis and Preprocessing"
      ],
      "metadata": {
        "id": "jWIdJM14g0hf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_columns = ['id','label','text','subject','speaker','job title','state info','party','barely true','false','half true','mostly true','pants on fire','context']"
      ],
      "metadata": {
        "id": "O925aSBigiXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "BNDq7A9hgoQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.tsv',sep='\\t',header=None, names = dataset_columns)\n",
        "test = pd.read_csv('test.tsv',sep='\\t',header=None, names = dataset_columns)\n",
        "val = pd.read_csv('valid.tsv',sep='\\t',header=None, names = dataset_columns)"
      ],
      "metadata": {
        "id": "Zqxi9VKZgivf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPkrCjpzgkAz",
        "outputId": "9773fd8e-ec00-43fa-8ce8-29b6cd7eccf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id                  0\n",
            "label               0\n",
            "text                0\n",
            "subject             2\n",
            "speaker             2\n",
            "job title        2897\n",
            "state info       2208\n",
            "party               2\n",
            "barely true         2\n",
            "false               2\n",
            "half true           2\n",
            "mostly true         2\n",
            "pants on fire       2\n",
            "context           102\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_nas(df):\n",
        "  # get all indices where job title and state info are nas:\n",
        "  jt_indices = df[df[\"job title\"].isna()].index\n",
        "  si_indices = df[df[\"state info\"].isna()].index\n",
        "\n",
        "  df.loc[jt_indices,\"job title\"] = \"unk\"\n",
        "  df.loc[si_indices,\"state info\"] = \"unk\"\n",
        "\n",
        "  # dropping all other rows with nas\n",
        "  df.dropna(inplace=True)\n",
        "  df = df.reset_index(drop=True)\n",
        "\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "srK4M6lBgruL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = handle_nas(train)\n",
        "test = handle_nas(test)\n",
        "val = handle_nas(val)"
      ],
      "metadata": {
        "id": "0PBDbsqggtTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM With Count Vectorizer"
      ],
      "metadata": {
        "id": "Ximl3-Hwg8FW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Pre-Processing"
      ],
      "metadata": {
        "id": "f2B4UNI4hHju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import joblib\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "le = LabelEncoder()\n",
        "train_df = train\n",
        "test_df = test\n",
        "val_df = val\n",
        "\n",
        "train_df['label'] = le.fit_transform(train_df['label'])\n",
        "val_df['label'] = le.fit_transform(val_df['label'])\n",
        "test_df['label'] = le.transform(test_df['label'])\n",
        "\n",
        "# Tokenize the text data\n",
        "vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n",
        "X_train_text = vectorizer.fit_transform(train_df['text']).toarray()\n",
        "X_val_text = vectorizer.transform(val_df['text']).toarray()\n",
        "X_test_text = vectorizer.transform(test_df['text']).toarray()\n",
        "\n",
        "joblib.dump(vectorizer, 'count_vectorizer.pkl')\n",
        "\n",
        "y_train = torch.tensor(train_df['label'].values, dtype=torch.long)\n",
        "y_val = torch.tensor(val_df['label'].values, dtype=torch.long)\n",
        "y_test = torch.tensor(test_df['label'].values, dtype=torch.long)\n",
        "\n",
        "\n",
        "X_train = torch.tensor(X_train_text, dtype=torch.float32)\n",
        "X_val = torch.tensor(X_val_text, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test_text, dtype=torch.float32)\n",
        "\n",
        "\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "nEYIn6FcgxWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "NF8-3wKbhKnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LSTM model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        out = self.softmax(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "2NyQEFtfhFqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Instantiation and Training"
      ],
      "metadata": {
        "id": "glvWqgLuhTNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "input_size = X_train.shape[1]\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "output_size = len(le.classes_)\n",
        "model_LSTM_CountVectorizer = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
        "torch.save(model_LSTM_CountVectorizer, 'model_LSTM_CountVectorizer.pth')\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_LSTM_CountVectorizer.parameters(), lr=0.001)\n",
        "\n",
        "# Training the model\n",
        "num_epochs = 3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model_LSTM_CountVectorizer.train()\n",
        "    batch_num = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_LSTM_CountVectorizer(inputs.unsqueeze(1)).to(device)\n",
        "        loss = criterion(outputs.to(device), labels.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        batch_num += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXm_5lhzhQMq",
        "outputId": "3da2b887-ef79-4b1d-f547-5c30c5a76725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation and Testing"
      ],
      "metadata": {
        "id": "qh5ik1MKhWx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate the model on the validation set\n",
        "model_LSTM_CountVectorizer.eval()\n",
        "with torch.no_grad():\n",
        "    all_preds_val = []\n",
        "    all_labels_val = []\n",
        "    for inputs, labels in val_loader:\n",
        "        outputs = model_LSTM_CountVectorizer(inputs.unsqueeze(1)).to(device)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds_val.extend(preds.cpu().numpy())\n",
        "        all_labels_val.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calculate validation accuracy\n",
        "accuracy_val = accuracy_score(all_labels_val, all_preds_val)\n",
        "print(f'Validation Accuracy: {accuracy_val}')\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "model_LSTM_CountVectorizer.eval()\n",
        "with torch.no_grad():\n",
        "    all_preds_test = []\n",
        "    all_labels_test = []\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model_LSTM_CountVectorizer(inputs.unsqueeze(1)).to(device)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds_test.extend(preds.cpu().numpy())\n",
        "        all_labels_test.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calculate test accuracy\n",
        "accuracy_test = accuracy_score(all_labels_test, all_preds_test)\n",
        "print(f'Test Accuracy: {accuracy_test}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3KUKhQrhWKK",
        "outputId": "30a5a6ef-13c2-435f-8fa5-a121bcda181b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.22562893081761007\n",
            "Test Accuracy: 0.2208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hybrid Model With LSTM"
      ],
      "metadata": {
        "id": "UcHYQfOrh9bP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Pre-Processing"
      ],
      "metadata": {
        "id": "BzY5fBpOiI_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Assuming you have separate DataFrames for train_df, val_df, and test_df\n",
        "train_df = train\n",
        "test_df = test\n",
        "val_df = val\n",
        "\n",
        "text_tfidf_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 3))\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "train_df['subject_encoded'] = label_encoder.fit_transform(train_df['subject'])\n",
        "train_df['context_encoded'] = label_encoder.fit_transform(train_df['context'])\n",
        "train_df['speaker_encoded'] = label_encoder.fit_transform(train_df['speaker'])\n",
        "train_df['party_encoded'] = label_encoder.fit_transform(train_df['party'])\n",
        "train_df['state_encoded'] = label_encoder.fit_transform(train_df['state info'])\n",
        "\n",
        "unknown_subject_val = val_df['subject'].unique()\n",
        "val_df['subject_encoded'] = val_df['subject'].apply(lambda x: label_encoder.transform([x])[0] if x not in unknown_subject_val else -1)\n",
        "unknown_context_val = val_df['context'].unique()\n",
        "val_df['context_encoded'] = val_df['context'].apply(lambda x: label_encoder.transform([x])[0] if x not in unknown_context_val else -1)\n",
        "unknown_speakers_val = val_df['speaker'].unique()\n",
        "val_df['speaker_encoded'] = val_df['speaker'].apply(lambda x: label_encoder.transform([x])[0] if x not in unknown_speakers_val else -1)\n",
        "unknown_party_val = val_df['party'].unique()\n",
        "val_df['party_encoded'] = val_df['party'].apply(lambda x: label_encoder.transform([x])[0] if x not in unknown_party_val else -1)\n",
        "unknown_state_val = val_df['state info'].unique()\n",
        "val_df['state_encoded'] = val_df['state info'].apply(lambda x: label_encoder.transform([x])[0] if x not in unknown_state_val else -1)\n",
        "\n",
        "unknown_subject_test = test_df['subject'].unique()\n",
        "test_df['subject_encoded'] = test_df['subject'].apply(lambda x: label_encoder.transform([x])[0] if x not in unknown_subject_test else -1)\n",
        "unknown_context_test = test_df['context'].unique()\n",
        "test_df['context_encoded'] = test_df['context'].apply(lambda x: label_encoder.transform([x])[0] if x not in unknown_context_test else -1)\n",
        "unknown_speakers_test = test_df['speaker'].unique()\n",
        "test_df['speaker_encoded'] = test_df['speaker'].apply(lambda x: label_encoder.transform([x])[0] if x not in unknown_speakers_test else -1)\n",
        "unknown_party_test = test_df['party'].unique()\n",
        "test_df['party_encoded'] = test_df['party'].apply(lambda x: label_encoder.transform([x])[0] if x not in unknown_party_test else -1)\n",
        "unknown_state_test = test_df['state info'].unique()\n",
        "test_df['state_encoded'] = test_df['state info'].apply(lambda x: label_encoder.transform([x])[0] if x not in unknown_state_test else -1)\n",
        "\n",
        "def combine_features(df):\n",
        "\n",
        "    speaker_encoded_tensor = torch.tensor(df['speaker_encoded'].values.reshape(-1, 1), dtype=torch.float32)\n",
        "    party_encoded_tensor = torch.tensor(df['party_encoded'].values.reshape(-1, 1), dtype=torch.float32)\n",
        "    state_encoded_tensor = torch.tensor(df['state_encoded'].values.reshape(-1, 1), dtype=torch.float32)\n",
        "    subject_encoded_tensor = torch.tensor(df['subject_encoded'].values.reshape(-1, 1), dtype=torch.float32)\n",
        "    context_encoded_tensor = torch.tensor(df['context_encoded'].values.reshape(-1, 1), dtype=torch.float32)\n",
        "\n",
        "    return torch.tensor(\n",
        "        torch.cat([\n",
        "            speaker_encoded_tensor,\n",
        "            party_encoded_tensor,\n",
        "            state_encoded_tensor,\n",
        "            subject_encoded_tensor,\n",
        "            context_encoded_tensor\n",
        "        ], dim=1),\n",
        "        dtype=torch.float32\n",
        "    )\n",
        "\n",
        "X_text_train = torch.tensor(text_tfidf_vectorizer.fit_transform(train_df['text']).toarray(), dtype=torch.float32)\n",
        "X_text_val = torch.tensor(text_tfidf_vectorizer.transform(val_df['text']).toarray(), dtype=torch.float32)\n",
        "X_text_test = torch.tensor(text_tfidf_vectorizer.transform(test_df['text']).toarray(), dtype=torch.float32)\n",
        "\n",
        "# Combine features\n",
        "X_train_combined = torch.tensor(\n",
        "    torch.cat([X_text_train, combine_features(train_df)], dim=1),\n",
        "    dtype=torch.float32\n",
        ")\n",
        "\n",
        "X_val_combined = torch.tensor(\n",
        "    torch.cat([X_text_val, combine_features(val_df)], dim=1),\n",
        "    dtype=torch.float32\n",
        ")\n",
        "\n",
        "X_test_combined = torch.tensor(\n",
        "    torch.cat([X_text_test, combine_features(test_df)], dim=1),\n",
        "    dtype=torch.float32\n",
        ")\n",
        "\n",
        "# Output labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = torch.tensor(label_encoder.fit_transform(train_df['label']), dtype=torch.long)\n",
        "y_val = torch.tensor(label_encoder.transform(val_df['label']), dtype=torch.long)\n",
        "y_test = torch.tensor(label_encoder.transform(test_df['label']), dtype=torch.long)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFJB1DB7h2V9",
        "outputId": "cb351c6d-7ab5-44ee-d5de-387b9c86463e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-5ec5b16b3293>:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.tensor(\n",
            "<ipython-input-12-5ec5b16b3293>:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_train_combined = torch.tensor(\n",
            "<ipython-input-12-5ec5b16b3293>:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_val_combined = torch.tensor(\n",
            "<ipython-input-12-5ec5b16b3293>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_test_combined = torch.tensor(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "K9YDG6HeiQyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, text_input_size, other_input_size, hidden_size, lstm_hidden_size, output_size, dropout_rate=0.5):\n",
        "        super(HybridModel, self).__init__()\n",
        "        # LSTM layer for text features\n",
        "        self.lstm = nn.LSTM(text_input_size, lstm_hidden_size, bidirectional=True, batch_first=True)\n",
        "        # Linear layers for other features\n",
        "        self.fc_other = nn.Sequential(\n",
        "            nn.Linear(other_input_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate)\n",
        "        )\n",
        "        # Final linear layer for classification\n",
        "        self.fc = nn.Linear(hidden_size + lstm_hidden_size * 2, output_size)\n",
        "\n",
        "    def forward(self, x_text, x_other):\n",
        "        # LSTM forward pass for text features\n",
        "        lstm_out, _ = self.lstm(x_text)\n",
        "        lstm_out = lstm_out[:, -1, :]\n",
        "        # Linear layers forward pass for other features\n",
        "        other_out = self.fc_other(x_other)\n",
        "        # Concatenate text and other features\n",
        "        combined = torch.cat([lstm_out, other_out], dim=1)\n",
        "\n",
        "        # Final classification layer\n",
        "        output = self.fc(combined)\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "NYTuk9qxiLVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Instatiation and Training"
      ],
      "metadata": {
        "id": "wt469vXliWMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_input_size = X_text_train.shape[1]\n",
        "other_input_size = X_train_combined.shape[1]\n",
        "hidden_size = 64\n",
        "lstm_hidden_size = 64\n",
        "output_size = len(label_encoder.classes_)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Instantiate the model\n",
        "model_Hybrid_Tfidf = HybridModel(text_input_size, other_input_size, hidden_size, lstm_hidden_size, output_size).to(device)\n",
        "torch.save(model_Hybrid_Tfidf,'model_Hybrid_Tfidf.pth')\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_Hybrid_Tfidf.parameters(), lr=0.001)\n",
        "\n",
        "# Combine text and other features for training, validation, and test sets\n",
        "X_train_text = X_text_train.unsqueeze(1)\n",
        "X_val_text = X_text_val.unsqueeze(1)\n",
        "X_test_text = X_text_test.unsqueeze(1)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "train_dataset = TensorDataset(X_train_text, X_train_combined, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model_Hybrid_Tfidf.train()\n",
        "    for batch_text, batch_other, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model_Hybrid_Tfidf(batch_text.to(device), batch_other.to(device)).to(device)\n",
        "        loss = criterion(output, labels.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n"
      ],
      "metadata": {
        "id": "J1w8MC_RiY2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation and Testing"
      ],
      "metadata": {
        "id": "rhaQ7GhCia6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation\n",
        "model_Hybrid_Tfidf.eval()\n",
        "with torch.no_grad():\n",
        "    val_output = model_Hybrid_Tfidf(X_val_text.to(device), X_val_combined.to(device)).to(device)\n",
        "    val_predictions = torch.argmax(val_output, dim=1)\n",
        "    val_accuracy = accuracy_score(y_val.cpu().numpy(), val_predictions.cpu().numpy())\n",
        "\n",
        "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Test\n",
        "model_Hybrid_Tfidf.eval()\n",
        "with torch.no_grad():\n",
        "    test_output = model_Hybrid_Tfidf(X_test_text.to(device), X_test_combined.to(device)).to(device)\n",
        "    test_predictions = torch.argmax(test_output, dim=1)\n",
        "    test_accuracy = accuracy_score(y_test.cpu().numpy(), test_predictions.cpu().numpy())\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YO6d_CzCicc5",
        "outputId": "298a1d15-256c-4d4a-bfaf-a1d9baa3ef7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 25.94%\n",
            "Test Accuracy: 24.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Load the CountVectorizer\n",
        "loaded_vectorizer = joblib.load('count_vectorizer.pkl')\n",
        "\n",
        "# New data to transform\n",
        "new_corpus = [\"A new sentence to transform.\"]\n",
        "\n",
        "# Transform the new data using the loaded CountVectorizer\n",
        "X_new = loaded_vectorizer.transform(new_corpus)\n",
        "\n",
        "# X_new is now a sparse matrix representing the new data in the vectorized form\n",
        "print(X_new.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvds4j45kn0V",
        "outputId": "8df85563-b6e0-4e62-b106-a95491358d6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Load the model\n",
        "loaded_model = torch.load('model_LSTM_CountVectorizer.pth')\n",
        "\n",
        "# Set the model to evaluation mode (if needed)\n",
        "loaded_model.eval()\n",
        "\n",
        "# New data for prediction\n",
        "new_data = torch.tensor(X_new.toarray(),dtype=torch.float)  # Replace with your actual input data\n",
        "\n",
        "# Make predictions\n",
        "with torch.no_grad():\n",
        "    predictions = loaded_model(new_data.unsqueeze(1))\n",
        "\n",
        "# Display the predictions\n",
        "print(torch.argmax(predictions, dim=1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Uza0rNU_uyD",
        "outputId": "473d026d-19e1-4dee-fd11-52c1d95b7db7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KndgNsh8AKTz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}